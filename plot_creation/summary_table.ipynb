{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e482ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, PredefinedSplit\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_datasets = {i: pd.read_csv(f\"datasets/group/{i}.csv\", index_col=[0]) for i in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1434cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\"logistic\": [], \"random_forest\": [], \"xgboost\": []}\n",
    "\n",
    "for i in range(20):\n",
    "    best_models[\"logistic\"].append(joblib.load(f\"best_models/logreg_{i}.model\"))\n",
    "    best_models['random_forest'].append(joblib.load(f\"best_models/rf_{i}.model\"))\n",
    "    best_models[\"xgboost\"].append(joblib.load(f\"best_models/xgboost_{i}.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data = pd.read_csv(\"fire/fire_df.csv\", index_col=[0])\n",
    "fire_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_distribution_df = pd.read_csv(\"fire/fire_distribution.csv\", index_col=[0])[3:].T\n",
    "fire_distribution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = {}\n",
    "\n",
    "for cls in fire_data[\"SIZECLASS\"].unique():\n",
    "    index_dict[cls] = list(fire_data[fire_data[\"SIZECLASS\"] == cls].index)\n",
    "\n",
    "distribution = []\n",
    "\n",
    "for cls in fire_distribution_df.columns:\n",
    "    distribution += [cls] * fire_distribution_df.loc['0', cls]\n",
    "    \n",
    "def calc_damage_estimate(profile, n):\n",
    "    estimates = []\n",
    "    \n",
    "    for test in range(n):\n",
    "        damage_in_dollar = 0\n",
    "        total_area = 0\n",
    "        \n",
    "        while total_area < profile:\n",
    "            sample_class = distribution[random.randint(0, len(distribution))-1]\n",
    "            i = index_dict[sample_class][random.randint(0, len(index_dict[sample_class])-1)]\n",
    "            \n",
    "            cost = fire_data.loc[i, \"COST\"]\n",
    "            km_squared = fire_data.loc[i, \"TOTALKM^2\"]\n",
    "\n",
    "            if (total_area + km_squared) > profile:\n",
    "                damage_in_dollar += (profile - total_area) / km_squared * cost\n",
    "            else:\n",
    "                damage_in_dollar += cost\n",
    "            total_area += km_squared\n",
    "\n",
    "        estimates.append(damage_in_dollar)\n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2203010",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_scale_param_df = pd.read_csv(\"optimal_scale_params.csv\", index_col=[0])\n",
    "optimal_scale_param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_estimates = {k: {i: [] for i in range(2015, 2020)} for k in ['Logisztikus regresszió', 'Random Forest', 'XGBRegressor']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv(\"data/datasets/static_variables.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b44071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_month_dict_logreg = {k: {i: {j: 0 for j in range(1, 13)} for i in range(2015, 2020)} for k in range(20)}\n",
    "year_month_dict_rf = {k: {i: {j: 0 for j in range(1, 13)} for i in range(2015, 2020)} for k in range(20)}\n",
    "year_month_dict_xgboost = {k: {i: {j: 0 for j in range(1, 13)} for i in range(2015, 2020)} for k in range(20)}\n",
    "\n",
    "for year in range(2015, 2020):\n",
    "    for month in range(1, 13):\n",
    "        print(year, month)\n",
    "        df = pd.read_csv(f\"data/datasets/raw_datasets/{year}-{month}.csv\", index_col=[0])\n",
    "        df = pd.concat([static_df, df], axis=1)\n",
    "        \n",
    "        df.drop(columns=['TARGET'], inplace=True)\n",
    "        for j in range(20):\n",
    "            print('\\t', j)\n",
    "            model = best_models[\"logistic\"][j]\n",
    "\n",
    "            y_preds = np.sum(optimal_scale_param_df.loc[j, 'logistic'] * model.predict_proba(df)[:, 1])\n",
    "            \n",
    "            year_month_dict_logreg[j][year][month] = y_preds\n",
    "\n",
    "            #####\n",
    "\n",
    "            model = best_models[\"random_forest\"][j]\n",
    "\n",
    "            y_preds = np.sum(optimal_scale_param_df.loc[j, 'random_forest'] * model.predict(df))\n",
    "            \n",
    "            year_month_dict_rf[j][year][month] = y_preds\n",
    "\n",
    "            ######\n",
    "\n",
    "            model = best_models[\"xgboost\"][j]\n",
    "\n",
    "            y_preds = np.sum(optimal_scale_param_df.loc[j, 'xgboost'] * model.predict(df))\n",
    "            \n",
    "            year_month_dict_xgboost[j][year][month] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_estimates = {k: {i: [] for i in range(2015, 2020)} for k in ['Logisztikus regresszió', 'Random Forest', 'XGBRegressor']}\n",
    "\n",
    "for i, year_dict in year_month_dict_logreg.items():\n",
    "    for y, vals in year_dict.items():\n",
    "        yearly_estimates['Logisztikus regresszió'][y] += calc_damage_estimate(np.sum(list(vals.values())), 25)\n",
    "        \n",
    "for i, year_dict in year_month_dict_rf.items():\n",
    "    for y, vals in year_dict.items():\n",
    "        yearly_estimates['Random Forest'][y] += calc_damage_estimate(np.sum(list(vals.values())), 25)\n",
    "        \n",
    "for i, year_dict in year_month_dict_xgboost.items():\n",
    "    for y, vals in year_dict.items():\n",
    "        yearly_estimates['XGBRegressor'][y] += calc_damage_estimate(np.sum(list(vals.values())), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(yearly_estimates['Logisztikus regresszió']).to_csv(f\"data/output/projection_results/train_log_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['Random Forest']).to_csv(f\"data/output/projection_results/train_rf_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['XGBRegressor']).to_csv(f\"data/output/projection_results/train_xgb_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bcfa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {\"Logisztikus regresszió\": 'log_df.csv', 'Random Forest': 'rf_df.csv', 'XGBRegressor': 'xgb_df.csv'}\n",
    "\n",
    "ssp5 = None\n",
    "ssp2 = None\n",
    "\n",
    "for model_name in ['Logisztikus regresszió', 'Random Forest', 'XGBRegressor']:\n",
    "    df_train = pd.read_csv(f\"data/output/projection_results/train_{name_dict[model_name]}\", index_col=[0]) / 10**9 \n",
    "    \n",
    "    df_test_valid = pd.read_csv(f\"data/output/projection_results/test_valid_{name_dict[model_name]}\", index_col=[0]) / 10**9 \n",
    "    \n",
    "    df_ssp5 = pd.read_csv(f\"data/output/projection_results/SSP5_{name_dict[model_name]}\", index_col=[0]) / 10**9\n",
    "    \n",
    "    df_ssp2 = pd.read_csv(f\"data/output/projection_results/SSP2_{name_dict[model_name]}\", index_col=[0]) / 10**9\n",
    "    \n",
    "    if ssp5 is None:\n",
    "        ssp5 = pd.concat([df_train.median(),\n",
    "           df_test_valid['2020'].median(),\n",
    "           df_test_valid['2021'].median(),\n",
    "           df_ssp5.median()])\n",
    "    else:\n",
    "        ssp5 = pd.concat([ssp5, pd.concat([df_train.median(),\n",
    "           df_test_valid['2020'].median(),\n",
    "           df_test_valid['2021'].median(),\n",
    "           df_ssp5.median()])], axis=1)\n",
    "    \n",
    "    if ssp2 is None:\n",
    "        ssp2 = pd.concat([df_train.median(),\n",
    "           df_test_valid['2020'].median(),\n",
    "           df_test_valid['2021'].median(),\n",
    "           df_ssp2.median()])\n",
    "    else:\n",
    "        ssp2 = pd.concat([ssp2, pd.concat([df_train.median(),\n",
    "           df_test_valid['2020'].median(),\n",
    "           df_test_valid['2021'].median(),\n",
    "           df_ssp2.median()])], axis=1)\n",
    "\n",
    "official_est = pd.Series([4.71, 0.48, 18.01, 26.35, 0.16, 12.08, '-'] + ['-']*25, name='Hivatalos becslés',\n",
    "                        index=ssp2.index)\n",
    "\n",
    "output = pd.concat([ssp5, official_est, ssp2], axis=1)\n",
    "\n",
    "output.columns = pd.MultiIndex.from_tuples([('SSP5', 'Logisztikus regresszió'), ('SSP5', 'Random Forest'), ('SSP5', 'XGBoost'),\n",
    "                                            ('', 'Hivatalos becslés'),\n",
    "                 ('SSP2', 'Logisztikus regresszió'), ('SSP2', 'Random Forest'), ('SSP2', 'XGBoost')], names=['Szcenárió', 'Modell'])\n",
    "\n",
    "k = [output[col][7:].median() for col in output.columns if 'Hivatalos becslés' not in col]\n",
    "\n",
    "k = k[:3] + [''] + k[3:]\n",
    "\n",
    "old_ind = output.index.copy()\n",
    "\n",
    "output.loc[-1] = k\n",
    "\n",
    "output.index = list(old_ind) + ['2025-2049 mediánja']\n",
    "\n",
    "output.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
