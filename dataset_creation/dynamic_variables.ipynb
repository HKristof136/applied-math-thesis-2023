{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "from shapely import geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1615127",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_boundary_file_path = r\"data/input/us-state-boundaries.json\"\n",
    "\n",
    "with open(state_boundary_file_path) as file:\n",
    "    data = json.load(file)\n",
    "CA = data[0]['st_asgeojson']['geometry']['coordinates'][0][0]\n",
    "CA = geometry.Polygon(CA)\n",
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36873b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_csv(\"data/input/static_variables.csv\", index_col=[0])\n",
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d49c0",
   "metadata": {},
   "source": [
    "### Temperature and precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63927e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_dict = {}\n",
    "\n",
    "variable_dict = {\"PRCP\": None, \"TAVG\": None}\n",
    "\n",
    "path = \"data/input/WEATHER\"\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "        df = pd.read_csv(os.path.join(root, file))\n",
    "        \n",
    "        for variable in variable_dict:\n",
    "            if variable_dict[variable] is None:\n",
    "                variable_dict[variable] = df.pivot(index=\"DATE\",\n",
    "                                                   columns=[\"STATION\", \"LATITUDE\", \"LONGITUDE\"],\n",
    "                                                   values=variable)\n",
    "                \n",
    "            else:\n",
    "                sub_df = df.pivot(index=\"DATE\",\n",
    "                                  columns=[\"STATION\", \"LATITUDE\", \"LONGITUDE\"],\n",
    "                                  values=variable)\n",
    "                variable_dict[variable] = pd.concat([variable_dict[variable], sub_df], axis=1)\n",
    "    break\n",
    "    \n",
    "for variable, val in variable_dict.items():\n",
    "    val.to_csv(f\"data/input/WEATHER/{variable}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict = {'PRCP': None, 'TAVG': None}\n",
    "\n",
    "path = \"data/input/WEATHER\"\n",
    "\n",
    "for variable in variable_dict:\n",
    "    df = pd.read_csv(f\"data/input/WEATHER/{variable}.csv\", index_col=[0])\n",
    "    df = df[[col for col in df.columns if '.' not in col]]\n",
    "    \n",
    "    for i, row in df[240:].iterrows():\n",
    "        sub_df = df.loc[[\"LATITUDE\", \"LONGITUDE\", i], row[~pd.isna(row)].index]\n",
    "        vals = sub_df.values.T\n",
    "        month_df = pd.DataFrame({\"LONGITUDE\": vals[:, 1], \"LATITUDE\": vals[:, 0], \"VALUES\": vals[:, 2]})\n",
    "        \n",
    "        month_df['to_drop'] = month_df.apply(lambda x: '_'.join([str(x[\"LONGITUDE\"]), str(x[\"LATITUDE\"])]), axis=1)\n",
    "        month_df = month_df.drop_duplicates(subset=['to_drop'])\n",
    "        month_df = month_df.drop(columns=['to_drop'])\n",
    "\n",
    "        month_df.to_csv(f\"data/input/WEATHER/{variable}/station_data/{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188b215",
   "metadata": {},
   "source": [
    "### Drought index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a026ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://thredds.northwestknowledge.net/thredds/dodsC/agg_met_pdsi_1979_CurrentYear_CONUS.nc?lat[170:1:425],lon[0:1:250],daily_mean_palmer_drought_severity_index[2230:1:3100][170:1:425][0:1:250],day[2530:1:3100]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c61f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = netCDF4.Dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = dataset.variables['lat'][0:].data.flatten()\n",
    "lons = dataset.variables['lon'][0:].data.flatten()\n",
    "days = dataset.variables['day'][0:].data\n",
    "\n",
    "xx, yy = np.meshgrid(lons[::6], lats[::6])\n",
    "xx = xx.flatten()\n",
    "yy = yy.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a9218",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, day in enumerate(days[::2]):\n",
    "    dt = datetime.fromordinal(datetime(1900, 1, 1).toordinal() + int(day) - 2).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    start = time.time()\n",
    "    data = dataset.variables['daily_mean_palmer_drought_severity_index'][i][::6, ::6]\n",
    "    \n",
    "    df = pd.DataFrame({\"lon\": xx, \"lat\": yy, \"values\": data.flatten()})\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    if i == 0:\n",
    "        mask = df.apply(lambda x: CA.contains(geometry.Point(x[\"lon\"], x[\"lat\"])), axis=1).values\n",
    "    \n",
    "    df = df.loc[mask].reset_index(drop=True)\n",
    "    df.to_csv(f\"data/input/DROUGHT/grid_data/{dt}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838abe95",
   "metadata": {},
   "source": [
    "## After kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b4a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in [\"PRCP\", \"TAVG\"]:\n",
    "    for year in range(2015, 2022):\n",
    "        for month in range(1, 13):\n",
    "            dfs = []\n",
    "            for root, dirs, files in os.walk(f\"data/input/WEATHER/{variable}/kriged_data\"):\n",
    "                for file in files:\n",
    "                    y, m, _ = [int(x) for x in file[:-4].split(\"-\")]\n",
    "                    if (year == y) and (month == m):\n",
    "                        dfs.append(pd.read_csv(os.path.join(root, file), index_col=[0]))\n",
    "                    if len(dfs) == 9:\n",
    "                        break\n",
    "            pd.concat(dfs).to_csv(f'data/input/WEATHER/{variable}/monthly_data/{year}-{month}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ff9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {}\n",
    "\n",
    "for root, _, files in os.walk(\"data/input/DROUGHT/kriged_data\"):\n",
    "    for file in files:\n",
    "        name_split = file.split('-')\n",
    "        if (name_split[0], name_split[1]) not in month_dict:\n",
    "            month_dict[(name_split[0], name_split[1])] = []\n",
    "        month_dict[(name_split[0], name_split[1])].append(os.path.join(root, file))\n",
    "month_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ea626",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, paths in month_dict.items():\n",
    "    print(key)\n",
    "    daily_dict = {}\n",
    "    for path in paths:\n",
    "        daily_split = path.split('-')\n",
    "        if (daily_split[0][-4:], daily_split[1], daily_split[2][:-6]) not in daily_dict:\n",
    "            daily_dict[(daily_split[0][-4:], daily_split[1], daily_split[2][:-6])] = []\n",
    "        daily_dict[(daily_split[0][-4:], daily_split[1], daily_split[2][:-6])].append(path)\n",
    "    df = None\n",
    "    for day, day_paths in daily_dict.items():\n",
    "        sub_df = None\n",
    "        for day_path in day_paths:\n",
    "            if sub_df is None:\n",
    "                sub_df = pd.read_csv(day_path, index_col=[0])\n",
    "            else:\n",
    "                sub_df = pd.concat([sub_df, pd.read_csv(day_path, index_col=[0])])\n",
    "        if df is None:\n",
    "            df = sub_df.copy()\n",
    "        else:\n",
    "            df['kriged_val'] += sub_df['kriged_val']\n",
    "    \n",
    "    df['kriged_val'] = df['kriged_val'] / len(daily_dict)\n",
    "    \n",
    "    df.to_csv(f\"data/input/DROUGHT/monthly_data/{key[0]}-{key[1]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89151047",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_map = {1: [-1, -1, -1], 2: [0, -1, -1], 3: [0, 0, -1]}\n",
    "year_map.update({i: [0, 0, 0] for i in range(4, 13)})\n",
    "\n",
    "month_map = {1: [12, 11, 10], 2: [1, 12, 11], 3: [2, 1, 12]}\n",
    "month_map.update({i: [i-1, i-2, i-3] for i in range(4, 13)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2015, 2022):\n",
    "    for month in range(1, 13):\n",
    "    month_df = pd.DataFrame()\n",
    "    for variable in [\"PRCP\", \"TAVG\"]:\n",
    "        for i, (m, y) in enumerate(zip(month_map[int(month)], [int(year) + z for z in year_map[int(month)]])):\n",
    "            vals = pd.read_csv(f\"data/input/WEATHER/{variable}/monthly_data/{y}-{m}.csv\", \n",
    "                               index_col=[0])[\"kriged_val\"].values\n",
    "            print(variable, m, y, vals.shape)\n",
    "            month_df[f\"{variable}_prev{i+1}\"] = vals\n",
    "    \n",
    "    for i, (m, y) in enumerate(zip(month_map[int(month)], [int(year) + z for z in year_map[int(month)]])):\n",
    "        if len(str(m)) == 1:\n",
    "            m = f\"0{m}\"\n",
    "        vals = pd.read_csv(f\"data/input/DROUGHT/monthly_data/{y}-{m}.csv\", \n",
    "                           index_col=[0])[\"kriged_val\"].values\n",
    "        month_df[f\"PDSI_prev{i+1}\"] = vals\n",
    "\n",
    "    month_df.to_csv(f\"data/datasets/raw_datasets/{year}-{month}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c10ab",
   "metadata": {},
   "source": [
    "### Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/input/FIRE_DATABASE/S_USA.FinalFirePerimeter.gdb\")\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "isin_CA = set()\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    if row[\"geometry\"] is None:\n",
    "        continue\n",
    "    polygons = list(row[\"geometry\"].geoms)\n",
    "    for poly in polygons:\n",
    "        if CA.intersects(poly):\n",
    "            isin_CA.add(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gdf.loc[list(isin_CA)]\n",
    "\n",
    "indices = df[df[\"FIREYEAR\"] >= 2015]['DISCOVERYDATETIME'].dropna().index\n",
    "\n",
    "df = df.loc[indices]\n",
    "df[\"DISCOVERYDATETIME\"] = pd.to_datetime(df[\"DISCOVERYDATETIME\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5752b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_boundaries = {}\n",
    "\n",
    "for i, fire in df[\"geometry\"].to_dict().items():\n",
    "    fire_polygons = list(fire.geoms)\n",
    "    for j, fire_poly in enumerate(fire_polygons):\n",
    "        lon_max, lon_min = np.max(fire_poly.exterior.xy[0]), np.min(fire_poly.exterior.xy[0])\n",
    "        lat_max, lat_min = np.max(fire_poly.exterior.xy[1]), np.min(fire_poly.exterior.xy[1])\n",
    "        fire_boundaries[(i, j)] = (lon_max, lon_min, lat_max, lat_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv(\"data/datasets/static_variables.csv\", index_col=[0])\n",
    "\n",
    "for year in range(2015, 2022):\n",
    "    for month in range(1, 13):\n",
    "        month_df = pd.read_csv(f\"data/datasets/raw_datasets/{y}-{m}.csv\", index_col=[0])\n",
    "\n",
    "        if month == 12:\n",
    "            start = datetime.date(year, month, 1)\n",
    "            end = datetime.date(year+1, 1, 1)\n",
    "        else:\n",
    "            start = datetime.date(year, month, 1)\n",
    "            end = datetime.date(year, month + 1, 1)\n",
    "        sub_df = df[(df[\"DISCOVERYDATETIME\"] >= start) & (df[\"DISCOVERYDATETIME\"] < end)]\n",
    "        \n",
    "        monthly_fires = {}\n",
    "        \n",
    "        for i, fire in sub_df[\"geometry\"].to_dict().items():\n",
    "                fire_polygons = list(fire.geoms)\n",
    "                for j, fire_poly in enumerate(fire_polygons):\n",
    "                    monthly_fires[(i, j)] = fire_poly\n",
    "        \n",
    "        month_target_var = []\n",
    "        \n",
    "        for lon, lat in static_df[[\"lon\", \"lat\"]].values:\n",
    "            k = 0\n",
    "            for i, fire in monthly_fires.items():\n",
    "                f_bound = fire_boundaries[i]\n",
    "                if lon >= f_bound[0]:\n",
    "                    continue\n",
    "                elif lon <= f_bound[1]:\n",
    "                    continue\n",
    "                if lat >= f_bound[2]:\n",
    "                    continue\n",
    "                elif lat <= f_bound[3]:\n",
    "                    continue\n",
    "                else:\n",
    "                    if fire.contains(geometry.Point(lon, lat)):\n",
    "                        month_target_var.append(1)\n",
    "                        k = 1\n",
    "                        break\n",
    "            if not k:\n",
    "                month_target_var.append(0)\n",
    "                    \n",
    "        month_df['TARGET'] = month_target_var\n",
    "        \n",
    "        month_df.to_csv(f\"data/datasets/raw_datasets/{y}-{m}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
