{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f73320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, PredefinedSplit\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv(\"datasets/static_data.csv\", index_col=[0])\n",
    "\n",
    "validation_df = pd.read_csv(\"datasets/validation_2020.csv\", index_col=[0])\n",
    "validation_df = validation_df.drop(columns=[\"FBFM3\", \"FBFM12\", \"FBFM13\",\n",
    "                                            'TMIN_prev1', 'TMIN_prev2', 'TMIN_prev3',\n",
    "                                            'TMAX_prev1', 'TMAX_prev2', 'TMAX_prev3'])\n",
    "\n",
    "test_df = pd.read_csv(\"datasets/test_2021.csv\", index_col=[0])\n",
    "test_df = test_df.drop(columns=[\"FBFM3\", \"FBFM12\", \"FBFM13\",\n",
    "                                'TMIN_prev1', 'TMIN_prev2', 'TMIN_prev3',\n",
    "                                'TMAX_prev1', 'TMAX_prev2', 'TMAX_prev3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_datasets = {i: pd.read_csv(f\"datasets/group/{i}.csv\",\n",
    "                                  index_col=[0]).drop(columns=[\"FBFM3\", \"FBFM12\", \"FBFM13\",\n",
    "                                                               'TMIN_prev1', 'TMIN_prev2', 'TMIN_prev3',\n",
    "                                                               'TMAX_prev1', 'TMAX_prev2', 'TMAX_prev3']) for i in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_difference_score(clf, X, y):\n",
    "    y_preds = clf.predict_proba(X)[:, 1]\n",
    "    n = 426327\n",
    "    diffs = []\n",
    "    for i in range(12):\n",
    "        profile = np.sum(y[i*n:(i+1)*n])\n",
    "        predicted_profile = np.sum(y_preds[i*n:(i+1)*n])\n",
    "        diffs.append(abs(profile - predicted_profile))\n",
    "    return np.sum(diffs)\n",
    "\n",
    "def breach_score(clf, X, y):\n",
    "    y_preds = clf.predict_proba(X)[:, 1]\n",
    "    n = 426327\n",
    "    diffs = []\n",
    "    for i in range(12):\n",
    "        profile = np.sum(y[i*n:(i+1)*n])\n",
    "        predicted_profile = np.sum(y_preds[i*n:(i+1)*n])\n",
    "        if profile - predicted_profile <= 0:\n",
    "            diffs.append(1)\n",
    "        else:\n",
    "            diffs.append(0)\n",
    "    return np.sum(diffs)\n",
    "\n",
    "def roc_auc(clf, X, y):\n",
    "    y_preds = clf.predict_proba(X)[:, 1]\n",
    "    return roc_auc_score(y, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5c2e0",
   "metadata": {},
   "source": [
    "### Logisztikus regressziÃ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25399951",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_df in sample_datasets.items():\n",
    "    training_data = pd.concat([sample_df, validation_df])\n",
    "    training_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X_train = training_data[[col for col in training_data.columns if col != 'TARGET']]\n",
    "    \n",
    "    Y_train = training_data[\"TARGET\"]\n",
    "    \n",
    "    split_index = [-1] * sample_df.shape[0] + [0] * validation_df.shape[0]\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "    \n",
    "    model = LogisticRegression(solver='newton-cholesky')\n",
    "    \n",
    "    w = [{0: i, 1: 1} for i in range(50, 2001, 50)]\n",
    "    parameters = {'class_weight': [None] + w}\n",
    "    \n",
    "    selector = GridSearchCV(model, parameters, \n",
    "                            refit=False, cv=pds, scoring={'profile_diff': profile_difference_score,\n",
    "                                                          'breach_score': breach_score,\n",
    "                                                          'auc': roc_auc},\n",
    "                            verbose=3)\n",
    "    selector.fit(X_train, Y_train)\n",
    "    \n",
    "    pd.DataFrame(selector.cv_results_).to_csv(f\"models/hyperparam_data/logreg/{i}_gridsearch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675322d",
   "metadata": {},
   "source": [
    "## Tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52999b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_difference_score(clf, X, y):\n",
    "    y_preds = clf.predict(X)\n",
    "    n = 426327\n",
    "    diffs = []\n",
    "    for i in range(12):\n",
    "        profile = np.sum(y[i*n:(i+1)*n])\n",
    "        predicted_profile = np.sum(y_preds[i*n:(i+1)*n])\n",
    "        diffs.append(abs(profile - predicted_profile))\n",
    "    return np.sum(diffs)\n",
    "\n",
    "def breach_score(clf, X, y):\n",
    "    y_preds = clf.predict(X)\n",
    "    n = 426327\n",
    "    diffs = []\n",
    "    \n",
    "    for i in range(12):\n",
    "        profile = np.sum(y[i*n:(i+1)*n])\n",
    "        predicted_profile = np.sum(y_preds[i*n:(i+1)*n])\n",
    "        if profile - predicted_profile <= 0:\n",
    "            diffs.append(1)\n",
    "        else:\n",
    "            diffs.append(0)\n",
    "    return np.sum(diffs)\n",
    "\n",
    "def roc_auc(clf, X, y):\n",
    "    y_preds = clf.predict(X)\n",
    "    return roc_auc_score(y, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0159cc",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a172a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_df in sample_datasets.items():\n",
    "    training_data = pd.concat([sample_df, validation_df])\n",
    "    training_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X_train = training_data[[col for col in training_data.columns if col != 'TARGET']]\n",
    "    \n",
    "    Y_train = training_data[\"TARGET\"]\n",
    "    \n",
    "    split_index = [-1] * sample_df.shape[0] + [0] * validation_df.shape[0]\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "    \n",
    "    model = RandomForestRegressor(max_features= 'sqrt')\n",
    "    \n",
    "    parameters = {\n",
    "                    'n_estimators': [*range(50, 2001, 50)],\n",
    "                    'min_samples_leaf': [*range(250, 10001, 250)]\n",
    "                 }\n",
    "    \n",
    "    selector = RandomizedSearchCV(model, parameters, n_iter=50,\n",
    "                            refit=False, cv=pds, scoring={'profile_diff': profile_difference_score,\n",
    "                                                          'breach_score': breach_score,\n",
    "                                                          'auc': roc_auc},\n",
    "                            verbose=3, random_state=0)\n",
    "\n",
    "    selector.fit(X_train, Y_train)\n",
    "    \n",
    "    pd.DataFrame(selector.cv_results_).to_csv(f\"models/hyperparam_data/randomforest/{i}_gridsearch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3be9d1",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21139b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_df in sample_datasets.items():\n",
    "    training_data = pd.concat([sample_df, validation_df])\n",
    "    training_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X_train = training_data[[col for col in training_data.columns if col != 'TARGET']]\n",
    "    \n",
    "    Y_train = training_data[\"TARGET\"]\n",
    "    \n",
    "    split_index = [-1] * sample_df.shape[0] + [0] * validation_df.shape[0]\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "    \n",
    "    model = XGBRegressor()\n",
    "    \n",
    "    parameters = {'n_estimators': [*range(50, 2001, 50)],\n",
    "                 'max_depth': [2, 3, 5, 7, 9],\n",
    "                 'learning_rate': [i/10 for i in range(1, 11)]}\n",
    "    \n",
    "    selector = RandomizedSearchCV(model, parameters, n_iter=50,\n",
    "                            refit=False, cv=pds, scoring={'profile_diff': profile_difference_score,\n",
    "                                                          'breach_score': breach_score,\n",
    "                                                          'auc': roc_auc},\n",
    "                            verbose=3, random_state=0)\n",
    "    selector.fit(X_train, Y_train)\n",
    "    \n",
    "    pd.DataFrame(selector.cv_results_).to_csv(f\"models/hyperparam_data/xgboost/{i}_gridsearch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80daac58",
   "metadata": {},
   "source": [
    "### Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = None\n",
    "profile_diff = None\n",
    "breach_score = None\n",
    "\n",
    "for i in range(20):\n",
    "    df = pd.read_csv(f\"model_selection/logreg/{i}_gridsearch.csv\", index_col=[0])\n",
    "    params = df[\"param_class_weight\"][1:].apply(lambda x: eval(x)[0]).values\n",
    "    if auc is None:\n",
    "        auc = df[\"mean_test_auc\"].values\n",
    "    else:\n",
    "        auc = np.vstack([auc, df[\"mean_test_auc\"].values])\n",
    "    \n",
    "    if profile_diff is None:\n",
    "        profile_diff = df[\"mean_test_profile_diff\"].values\n",
    "    else:\n",
    "        profile_diff = np.vstack([profile_diff, df[\"mean_test_profile_diff\"].values])\n",
    "    \n",
    "    if breach_score is None:\n",
    "        breach_score = df[\"mean_test_breach_score\"].values\n",
    "    else:\n",
    "        breach_score = np.vstack([breach_score, df[\"mean_test_breach_score\"].values])\n",
    "\n",
    "auc = auc.T\n",
    "profile_diff = profile_diff.T\n",
    "breach_score = breach_score.T\n",
    "\n",
    "print(\"Logisztikus regressziÃ³\")\n",
    "print(\"\\tMaximum AUC: \", np.max(np.mean(auc, axis=1)))\n",
    "print(\"\\twith parameters: \", params[np.argmax(np.mean(auc, axis=1)) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = None\n",
    "profile_diff = None\n",
    "breach_score = None\n",
    "\n",
    "for i in range(20):\n",
    "    df = pd.read_csv(f\"model_selection/randomforest/{i}_gridsearch.csv\", index_col=[0])\n",
    "    params = df[\"params\"].apply(lambda x: eval(x)).values\n",
    "    if auc is None:\n",
    "        auc = df[\"mean_test_auc\"].values\n",
    "    else:\n",
    "        auc = np.vstack([auc, df[\"mean_test_auc\"].values])\n",
    "    \n",
    "    if profile_diff is None:\n",
    "        profile_diff = df[\"mean_test_profile_diff\"].values\n",
    "    else:\n",
    "        profile_diff = np.vstack([profile_diff, df[\"mean_test_profile_diff\"].values])\n",
    "    \n",
    "    if breach_score is None:\n",
    "        breach_score = df[\"mean_test_breach_score\"].values\n",
    "    else:\n",
    "        breach_score = np.vstack([breach_score, df[\"mean_test_breach_score\"].values])\n",
    "\n",
    "auc = auc.T\n",
    "profile_diff = profile_diff.T\n",
    "breach_score = breach_score.T\n",
    "\n",
    "print(\"Logisztikus regressziÃ³\")\n",
    "print(\"\\tMaximum AUC: \", np.max(np.mean(auc, axis=1)))\n",
    "print(\"\\twith parameters: \", params[np.argmax(np.mean(auc, axis=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = None\n",
    "profile_diff = None\n",
    "breach_score = None\n",
    "\n",
    "for i in range(20):\n",
    "    df = pd.read_csv(f\"model_selection/xgboost/{i}_gridsearch.csv\", index_col=[0])\n",
    "    params = df[\"params\"].apply(lambda x: eval(x)).values\n",
    "    if auc is None:\n",
    "        auc = df[\"mean_test_auc\"].values\n",
    "    else:\n",
    "        auc = np.vstack([auc, df[\"mean_test_auc\"].values])\n",
    "    \n",
    "    if profile_diff is None:\n",
    "        profile_diff = df[\"mean_test_profile_diff\"].values\n",
    "    else:\n",
    "        profile_diff = np.vstack([profile_diff, df[\"mean_test_profile_diff\"].values])\n",
    "    \n",
    "    if breach_score is None:\n",
    "        breach_score = df[\"mean_test_breach_score\"].values\n",
    "    else:\n",
    "        breach_score = np.vstack([breach_score, df[\"mean_test_breach_score\"].values])\n",
    "\n",
    "auc = auc.T\n",
    "profile_diff = profile_diff.T\n",
    "breach_score = breach_score.T\n",
    "\n",
    "print(\"XGBRegressor\")\n",
    "print(\"\\tMaximum AUC: \", np.max(np.mean(auc, axis=1)))\n",
    "print(\"\\twith parameters: \", params[np.argmax(np.mean(auc, axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193de73c",
   "metadata": {},
   "source": [
    "## Downscale optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_logistic(clf, X, y):\n",
    "    y_preds = clf.predict_proba(X)[:, 1]\n",
    "    \n",
    "    roc_auc = roc_auc_score(y, y_preds)\n",
    "    \n",
    "    n = 426327\n",
    "    diffs = []\n",
    "    \n",
    "    output_pairs = []\n",
    "    \n",
    "    for i in range(12):\n",
    "        profile = np.sum(y[i*n:(i+1)*n])\n",
    "        predicted_profile = np.sum(y_preds[i*n:(i+1)*n])\n",
    "        \n",
    "        output_pairs.append((profile, predicted_profile))\n",
    "        \n",
    "        diffs.append(abs(profile - predicted_profile))\n",
    "    return roc_auc, np.sum(diffs), output_pairs\n",
    "\n",
    "def scores_tree(clf, X, y):\n",
    "    y_preds = clf.predict(X)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y, y_preds)\n",
    "    \n",
    "    n = 426327\n",
    "    diffs = []\n",
    "    output_pairs = []\n",
    "    for i in range(12):\n",
    "        profile = np.sum(y[i*n:(i+1)*n])\n",
    "        predicted_profile = np.sum(y_preds[i*n:(i+1)*n])\n",
    "        \n",
    "        output_pairs.append((profile, predicted_profile))\n",
    "        \n",
    "        diffs.append(abs(profile - predicted_profile))\n",
    "    return roc_auc, np.sum(diffs), output_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = validation_df[\"TARGET\"]\n",
    "X_valid = validation_df[[col for col in validation_df if col != \"TARGET\"]]\n",
    "\n",
    "optimal_scale_params = {'logistic': [], 'random_forest': [], 'xgboost': []}\n",
    "\n",
    "for i, train_dataset in sample_datasets.items():\n",
    "    \n",
    "    y_train = train_dataset[\"TARGET\"].copy()\n",
    "    X_train = train_dataset[[col for col in train_dataset if col != \"TARGET\"]]\n",
    "    \n",
    "    model = LogisticRegression(class_weight={0: 1, 1: 1}, solver=\"newton-cholesky\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    roc_auc, profile_diff, output_pairs = scores_logistic(model, X_valid, y_valid)\n",
    "    \n",
    "    actual = np.array(output_pairs)[:, 0]\n",
    "    \n",
    "    preds = np.array(output_pairs)[:, 1]\n",
    "    \n",
    "    min_diff = np.sum((preds - actual) ** 2)\n",
    "    opt_c = 1\n",
    "\n",
    "    for d in np.linspace(0.0001, 2, 20000):\n",
    "        if min_diff > np.sum((d*preds - actual) ** 2):\n",
    "            min_diff = np.sum((d*preds - actual) ** 2)\n",
    "            opt_c = d\n",
    "    \n",
    "    optimal_scale_params['logistic'].append(opt_c)\n",
    "    \n",
    "    ##################################################\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=250, min_samples_leaf=500)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    roc_auc, profile_diff, output_pairs = scores_tree(model, X_valid, y_valid)\n",
    "    \n",
    "    actual = np.array(output_pairs)[:, 0]\n",
    "    \n",
    "    preds = np.array(output_pairs)[:, 1]\n",
    "    \n",
    "    min_diff = np.sum((preds - actual) ** 2)\n",
    "    opt_c = 1\n",
    "\n",
    "    for d in np.linspace(0.0001, 1, 10000):\n",
    "        if min_diff > np.sum((d*preds - actual) ** 2):\n",
    "            min_diff = np.sum((d*preds - actual) ** 2)\n",
    "            opt_c = d\n",
    "    \n",
    "    optimal_scale_params['random_forest'].append(opt_c)\n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    model = XGBRegressor(objective='binary:logistic', n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    roc_auc, profile_diff, output_pairs = scores_tree(model, X_valid, y_valid)\n",
    "\n",
    "    actual = np.array(output_pairs)[:, 0]\n",
    "    \n",
    "    preds = np.array(output_pairs)[:, 1]\n",
    "    \n",
    "    min_diff = np.sum((preds - actual) ** 2)\n",
    "    opt_c = 1\n",
    "\n",
    "    for d in np.linspace(0.0001, 1, 10000):\n",
    "        if min_diff > np.sum((d*preds - actual) ** 2):\n",
    "            min_diff = np.sum((d*preds - actual) ** 2)\n",
    "            opt_c = d\n",
    "    \n",
    "    optimal_scale_params['xgboost'].append(opt_c)\n",
    "    \n",
    "pd.DataFrame(optimal_scale_params).to_csv(\"models/optimal_scale_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208cb75",
   "metadata": {},
   "source": [
    "## Saving best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\"logistic\": [], \"random_forest\": [], \"xgboost\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b731ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, train_dataset in sample_datasets.items():\n",
    "    y_train = train_dataset[\"TARGET\"].copy()\n",
    "    X_train = train_dataset[[col for col in train_dataset if col != \"TARGET\"]]\n",
    "\n",
    "    model = LogisticRegression(class_weight={0: 1, 1: 1}, solver=\"newton-cholesky\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[\"logistic\"].append(model)\n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=250, min_samples_leaf=500)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[\"random_forest\"].append(model)\n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[\"xgboost\"].append(model)\n",
    "    \n",
    "import joblib\n",
    "\n",
    "for i in range(20):\n",
    "    joblib.dump(best_models['logistic'][i], f'models/best_models/logreg_{i}.model')\n",
    "    joblib.dump(best_models['random_forest'][i], f'models/best_models/rf_{i}.model')\n",
    "    joblib.dump(best_models['xgboost'][i], f'models/best_models/xgboost_{i}.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
