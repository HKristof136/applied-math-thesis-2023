{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, PredefinedSplit\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_datasets = {i: pd.read_csv(f\"data/datasets/final_datasets/{i}.csv\", index_col=[0]) for i in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\"logistic\": [], \"random_forest\": [], \"xgboost\": []}\n",
    "\n",
    "for i in range(20):\n",
    "    best_models[\"logistic\"].append(joblib.load(f\"best_models/logreg_{i}.model\"))\n",
    "    best_models['random_forest'].append(joblib.load(f\"best_models/rf_{i}.model\"))\n",
    "    best_models[\"xgboost\"].append(joblib.load(f\"best_models/xgboost_{i}.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data = pd.read_csv(\"data/input/FIRE/fire_df.csv\", index_col=[0])\n",
    "fire_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_distribution_df = pd.read_csv(\"data/input/FIRE/fire_distribution.csv\", index_col=[0])[3:].T\n",
    "fire_distribution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = {}\n",
    "\n",
    "for cls in fire_data[\"SIZECLASS\"].unique():\n",
    "    index_dict[cls] = list(fire_data[fire_data[\"SIZECLASS\"] == cls].index)\n",
    "\n",
    "distribution = []\n",
    "\n",
    "for cls in fire_distribution_df.columns:\n",
    "    distribution += [cls] * fire_distribution_df.loc['0', cls]\n",
    "    \n",
    "def calc_damage_estimate(profile, n):\n",
    "    estimates = []\n",
    "    \n",
    "    for test in range(n):\n",
    "        damage_in_dollar = 0\n",
    "        total_area = 0\n",
    "        \n",
    "        while total_area < profile:\n",
    "            sample_class = distribution[random.randint(0, len(distribution))-1]\n",
    "            i = index_dict[sample_class][random.randint(0, len(index_dict[sample_class])-1)]\n",
    "            \n",
    "            cost = fire_data.loc[i, \"COST\"]\n",
    "            km_squared = fire_data.loc[i, \"TOTALKM^2\"]\n",
    "\n",
    "            if (total_area + km_squared) > profile:\n",
    "                damage_in_dollar += (profile - total_area) / km_squared * cost\n",
    "            else:\n",
    "                damage_in_dollar += cost\n",
    "            total_area += km_squared\n",
    "\n",
    "        estimates.append(damage_in_dollar)\n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68181e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_scale_param_df = pd.read_csv(\"optimal_scale_params.csv\", index_col=[0])\n",
    "optimal_scale_param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c55341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/datasets/validation_2020.csv\", index_col=[0])[:426327]\n",
    "\n",
    "year_map = {1: [-1, -1, -1], 2: [0, -1, -1], 3: [0, 0, -1]}\n",
    "year_map.update({i: [0, 0, 0] for i in range(4, 13)})\n",
    "\n",
    "month_map = {1: [12, 11, 10], 2: [1, 12, 11], 3: [2, 1, 12]}\n",
    "month_map.update({i: [i-1, i-2, i-3] for i in range(4, 13)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e192c",
   "metadata": {},
   "source": [
    "## SSP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_estimates = {k: {i: [] for i in range(2025, 2050)} for k in ['Logisztikus regresszió', 'Random Forest', 'XGBRegressor']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77013f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"SSP5\"\n",
    "\n",
    "for year in range(2025, 2050):\n",
    "    start = time.time()\n",
    "    yearly_df = None\n",
    "    \n",
    "    for month in range(1, 13):\n",
    "        monthly_df = df.copy()\n",
    "        for i, (m, y) in enumerate(zip(month_map[month], [year + z for z in year_map[month]])):\n",
    "            drought_vals = pd.read_csv(f\"data/input/DROUGHT/{scenario}/monthly_data/{y}-{m}.csv\")[\"kriged_val\"].values\n",
    "            monthly_df[f'PDSI_prev{i+1}'] = drought_vals\n",
    "            \n",
    "            tavg_vals = pd.read_csv(f\"data/input/TAVG/{scenario}/monthly_data/{y}-{m}.csv\")[\"kriged_val\"].values\n",
    "            monthly_df[f'TAVG_prev{i+1}'] = tavg_vals\n",
    "            \n",
    "            prcp_vals = pd.read_csv(f\"data/input/PRCP/{scenario}/monthly_data/{y}-{m}.csv\")[\"kriged_val\"].values\n",
    "            monthly_df[f'PRCP_prev{i+1}'] = prcp_vals\n",
    "        \n",
    "        if yearly_df is None:\n",
    "            yearly_df = monthly_df.copy()\n",
    "        else:\n",
    "            yearly_df = pd.concat([yearly_df, monthly_df.copy()])\n",
    "    \n",
    "    for j in range(20):\n",
    "        model = best_models[\"logistic\"][j]\n",
    "            \n",
    "        y_preds = model.predict_proba(yearly_df)[:, 1]\n",
    "        \n",
    "        opt_c = optimal_scale_param_df.loc[j, 'logistic']\n",
    "        \n",
    "        yearly_estimates['Logisztikus regresszió'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "        \n",
    "        ######\n",
    "            \n",
    "        model = best_models[\"random_forest\"][j]\n",
    "            \n",
    "        y_preds = model.predict(yearly_df)\n",
    "        \n",
    "        opt_c = optimal_scale_param_df.loc[j, 'random_forest']\n",
    "            \n",
    "        yearly_estimates['Random Forest'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "        \n",
    "        ######\n",
    "            \n",
    "        model = best_models[\"xgboost\"][j]\n",
    "            \n",
    "        y_preds = model.predict(yearly_df)\n",
    "        \n",
    "        opt_c = optimal_scale_param_df.loc[j, 'xgboost']\n",
    "            \n",
    "        yearly_estimates['XGBRegressor'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb08154",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(yearly_estimates['Logisztikus regresszió']).to_csv(f\"data/output/projection_results/{scenario}_log_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['Random Forest']).to_csv(f\"data/output/projection_results/{scenario}_rf_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['XGBRegressor']).to_csv(f\"data/output/projection_results/{scenario}_xgb_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0c963",
   "metadata": {},
   "source": [
    "## SSP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c901404",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_estimates = {k: {i: [] for i in range(2025, 2050)} for k in ['Logisztikus regresszió', 'Random Forest', 'XGBRegressor']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"SSP2\"\n",
    "\n",
    "for year in range(2025, 2050):\n",
    "    start = time.time()\n",
    "    yearly_df = None\n",
    "    \n",
    "    for month in range(1, 13):\n",
    "        monthly_df = df.copy()\n",
    "        for i, (m, y) in enumerate(zip(month_map[month], [year + z for z in year_map[month]])):\n",
    "            drought_vals = pd.read_csv(f\"data/input/DROUGHT/{scenario}/monthly_data/{y}-{m}.csv\")[\"kriged_val\"].values\n",
    "            monthly_df[f'PDSI_prev{i+1}'] = drought_vals\n",
    "            \n",
    "            tavg_vals = pd.read_csv(f\"data/input/TAVG/{scenario}/monthly_data/{y}-{m}.csv\")[\"kriged_val\"].values\n",
    "            monthly_df[f'TAVG_prev{i+1}'] = tavg_vals\n",
    "            \n",
    "            prcp_vals = pd.read_csv(f\"data/input/PRCP/{scenario}/monthly_data/{y}-{m}.csv\")[\"kriged_val\"].values\n",
    "            monthly_df[f'PRCP_prev{i+1}'] = prcp_vals\n",
    "        \n",
    "        if yearly_df is None:\n",
    "            yearly_df = monthly_df.copy()\n",
    "        else:\n",
    "            yearly_df = pd.concat([yearly_df, monthly_df.copy()])\n",
    "    \n",
    "    for j in range(20):\n",
    "        model = best_models[\"logistic\"][j]\n",
    "            \n",
    "        y_preds = model.predict_proba(yearly_df)[:, 1]\n",
    "        \n",
    "        opt_c = optimal_scale_param_df.loc[j, 'logistic']\n",
    "        \n",
    "        yearly_estimates['Logisztikus regresszió'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "        \n",
    "        ######\n",
    "            \n",
    "        model = best_models[\"random_forest\"][j]\n",
    "            \n",
    "        y_preds = model.predict(yearly_df)\n",
    "        \n",
    "        opt_c = optimal_scale_param_df.loc[j, 'random_forest']\n",
    "            \n",
    "        yearly_estimates['Random Forest'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "        \n",
    "        ######\n",
    "            \n",
    "        model = best_models[\"xgboost\"][j]\n",
    "            \n",
    "        y_preds = model.predict(yearly_df)\n",
    "        \n",
    "        opt_c = optimal_scale_param_df.loc[j, 'xgboost']\n",
    "            \n",
    "        yearly_estimates['XGBRegressor'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(yearly_estimates['Logisztikus regresszió']).to_csv(f\"data/output/projection_results/{scenario}_log_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['Random Forest']).to_csv(f\"data/output/projection_results/{scenario}_rf_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['XGBRegressor']).to_csv(f\"data/output/projection_results/{scenario}_xgb_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb54a7",
   "metadata": {},
   "source": [
    "## 2020 and 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('data/datasets/validation_2020.csv', index_col=[0])\n",
    "\n",
    "test_df = pd.read_csv('data/datasets/test_2021.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_estimates = {'Logisztikus regresszió': {2020, 2021: []},\n",
    "                   'Random Forest': {2020, 2021: []},\n",
    "                   'XGBRegressor': {2020, 2021: []}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "\n",
    "for j in range(20):\n",
    "    model = best_models[\"logistic\"][j]\n",
    "        \n",
    "    y_preds = model.predict_proba(test_df)[:, 1]\n",
    "    \n",
    "    opt_c = optimal_scale_param_df.loc[j, 'logistic']\n",
    "    \n",
    "    yearly_estimates['Logisztikus regresszió'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "    \n",
    "    ######\n",
    "        \n",
    "    model = best_models[\"random_forest\"][j]\n",
    "        \n",
    "    y_preds = model.predict(test_df)\n",
    "    \n",
    "    opt_c = optimal_scale_param_df.loc[j, 'random_forest']\n",
    "        \n",
    "    yearly_estimates['Random Forest'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "    \n",
    "    ######\n",
    "        \n",
    "    model = best_models[\"xgboost\"][j]\n",
    "        \n",
    "    y_preds = model.predict(test_df)\n",
    "    \n",
    "    opt_c = optimal_scale_param_df.loc[j, 'xgboost']\n",
    "        \n",
    "    yearly_estimates['XGBRegressor'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "\n",
    "for j in range(20):\n",
    "    model = best_models[\"logistic\"][j]\n",
    "        \n",
    "    y_preds = model.predict_proba(validation_df)[:, 1]\n",
    "    \n",
    "    opt_c = optimal_scale_param_df.loc[j, 'logistic']\n",
    "    \n",
    "    yearly_estimates['Logisztikus regresszió'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "    \n",
    "    ######\n",
    "        \n",
    "    model = best_models[\"random_forest\"][j]\n",
    "        \n",
    "    y_preds = model.predict(validation_df)\n",
    "    \n",
    "    opt_c = optimal_scale_param_df.loc[j, 'random_forest']\n",
    "        \n",
    "    yearly_estimates['Random Forest'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)\n",
    "    \n",
    "    ######\n",
    "        \n",
    "    model = best_models[\"xgboost\"][j]\n",
    "        \n",
    "    y_preds = model.predict(validation_df)\n",
    "    \n",
    "    opt_c = optimal_scale_param_df.loc[j, 'xgboost']\n",
    "        \n",
    "    yearly_estimates['XGBRegressor'][year] += calc_damage_estimate(opt_c * np.sum(y_preds), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(yearly_estimates['Logisztikus regresszió']).to_csv(f\"data/output/projection_results/test_valid_log_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['Random Forest']).to_csv(f\"data/output/projection_results/test_valid_rf_df.csv\")\n",
    "pd.DataFrame(yearly_estimates['XGBRegressor']).to_csv(f\"data/output/projection_results/test_valid_xgb_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf1c04",
   "metadata": {},
   "source": [
    "# Projection results plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4b060",
   "metadata": {},
   "source": [
    "### SSP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47953ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"SSP2\"\n",
    "\n",
    "name_dict = {\"Logisztikus regresszió\": 'log_df.csv', 'Random Forest': 'rf_df.csv', 'XGBRegressor': 'xgb_df.csv'}\n",
    "\n",
    "for model_name in ['Logisztikus regresszió', 'Random Forest', 'XGBRegressor']:\n",
    "    test_valid_df = pd.read_csv(f\"data/output/projection_results/test_valid_{name_dict[model_name]}\", index_col=[0]) / 10**9\n",
    "    \n",
    "    proj_df = pd.read_csv(f\"data/output/projection_results/{scenario}_{name_dict[model_name]}\", index_col=[0]) / 10**9\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 5))\n",
    "    \n",
    "    k = 1\n",
    "    \n",
    "    to_plot = [test_valid_df['2020'], test_valid_df['2021'], [], [], []] + [proj_df[col] for col in proj_df.columns][::k]\n",
    "    \n",
    "    fit_poly = [proj_df[col] for col in proj_df.columns][::k]\n",
    "    \n",
    "    ax.boxplot(to_plot)\n",
    "    \n",
    "    ax.plot([*range(6, len(fit_poly) + 6)], np.poly1d(np.polyfit([*range(6, len(fit_poly) + 6)], \n",
    "                                                        [proj_df[col].mean() for col in proj_df.columns][::k],\n",
    "                                                        1))([*range(6, len(fit_poly) + 6)]), c='red', label='lineáris regresszió az átlagokra')\n",
    "    \n",
    "    coef = np.polyfit([*range(6, len(fit_poly)+6)], [proj_df[col].mean() for col in proj_df.columns][::k], 1)\n",
    "    \n",
    "    print(coef[0])\n",
    "    \n",
    "    ax.plot([], [], ' ', label=f'meredekség: {coef[0]:.5f}')\n",
    "    \n",
    "    tick_labels = ['', '2021', '', '', '']\n",
    "    for j in [str(i) for i in range(2025, 2050)][::2]:\n",
    "        tick_labels += [j, '']\n",
    "    \n",
    "    ax.set_xticklabels(tick_labels[:-1])\n",
    "    \n",
    "    ax.tick_params(axis='both', labelsize=16)\n",
    "    ax.set_ylabel(\"$mrd\", fontsize=16)\n",
    "    \n",
    "    ax.set_title(scenario + ' ' + model_name, fontsize=24, pad=10)\n",
    "    \n",
    "    ax.set_ylim(3, 58)\n",
    "    \n",
    "    plt.legend(loc='upper left', fontsize=14)\n",
    "    plt.savefig(f\"data/output/projected_results/{scenario}_{model_name.replace(' ', '_')}_{k}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5f910",
   "metadata": {},
   "source": [
    "### SSP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41024df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"SSP5\"\n",
    "\n",
    "name_dict = {\"Logisztikus regresszió\": 'log_df.csv', 'Random Forest': 'rf_df.csv', 'XGBRegressor': 'xgb_df.csv'}\n",
    "\n",
    "for model_name in ['Logisztikus regresszió', 'Random Forest', 'XGBRegressor']:\n",
    "    test_valid_df = pd.read_csv(f\"data/output/projection_results/test_valid_{name_dict[model_name]}\", index_col=[0]) / 10**9\n",
    "    \n",
    "    proj_df = pd.read_csv(f\"data/output/projection_results/{scenario}_{name_dict[model_name]}\", index_col=[0]) / 10**9\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 5))\n",
    "    \n",
    "    k = 1\n",
    "    \n",
    "    to_plot = [test_valid_df['2020'], test_valid_df['2021'], [], [], []] + [proj_df[col] for col in proj_df.columns][::k]\n",
    "    \n",
    "    fit_poly = [proj_df[col] for col in proj_df.columns][::k]\n",
    "    \n",
    "    ax.boxplot(to_plot)\n",
    "    \n",
    "    ax.plot([*range(6, len(fit_poly) + 6)], np.poly1d(np.polyfit([*range(6, len(fit_poly) + 6)], \n",
    "                                                        [proj_df[col].mean() for col in proj_df.columns][::k],\n",
    "                                                        1))([*range(6, len(fit_poly) + 6)]), c='red', label='lineáris regresszió az átlagokra')\n",
    "    \n",
    "    coef = np.polyfit([*range(6, len(fit_poly)+6)], [proj_df[col].mean() for col in proj_df.columns][::k], 1)\n",
    "    \n",
    "    print(coef[0])\n",
    "    \n",
    "    ax.plot([], [], ' ', label=f'meredekség: {coef[0]:.5f}')\n",
    "    \n",
    "    tick_labels = ['', '2021', '', '', '']\n",
    "    for j in [str(i) for i in range(2025, 2050)][::2]:\n",
    "        tick_labels += [j, '']\n",
    "    \n",
    "    ax.set_xticklabels(tick_labels[:-1])\n",
    "    \n",
    "    ax.tick_params(axis='both', labelsize=16)\n",
    "    ax.set_ylabel(\"$mrd\", fontsize=16)\n",
    "    \n",
    "    ax.set_title(scenario + ' ' + model_name, fontsize=24, pad=10)\n",
    "    \n",
    "    ax.set_ylim(3, 58)\n",
    "    \n",
    "    plt.legend(loc='upper left', fontsize=14)\n",
    "    plt.savefig(f\"data/output/projected_results/{scenario}_{model_name.replace(' ', '_')}_{k}.png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
